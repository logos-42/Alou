// @ts-nocheck
/*
  ä½¿ç”¨ Node.js åŸç”Ÿ https å®ç°å¯¹ DeepSeek/OpenAI å…¼å®¹æ¥å£çš„è°ƒç”¨ï¼Œ
  é¿å… axios å¸¦æ¥çš„ CommonJS åŒ…ç¼ºå¤±é—®é¢˜ï¼Œæ–¹ä¾¿ pkg æ‰“åŒ…ã€‚
*/

import * as https from 'https';
import { URL } from 'url';

export interface ParsedNeed {
  service_type: string;
  keywords: string[];
  action: 'search' | 'create';
  description: string;
  deep_need?: string;
  workflows?: { name: string; steps: string[] }[];
  mcp_tools?: { name: string; description: string }[];
}

export interface LLMConfig {
  apiKey: string;
  apiUrl: string;
  model: string;
}

function httpsRequest(urlStr: string, data: string, headers: Record<string, string>): Promise<string> {
  return new Promise((resolve, reject) => {
    const url = new URL(urlStr);

    const req = https.request({
      method: 'POST',
      hostname: url.hostname,
      port: url.port || 443,
      path: url.pathname + url.search,
      headers: {
        'Content-Type': 'application/json',
        'Content-Length': Buffer.byteLength(data),
        ...headers
      },
      timeout: 60000
    }, (res) => {
      let body = '';
      res.on('data', (chunk) => body += chunk);
      res.on('end', () => resolve(body));
    });

    req.on('error', reject);
    req.on('timeout', () => {
      req.destroy();
      reject(new Error('Request timeout'));
    });

    req.write(data);
    req.end();
  });
}

export async function askLLM(prompt: string, config?: Partial<LLMConfig>): Promise<string> {
  const apiKey = config?.apiKey || process.env.LLM_API_KEY || 'sk-392a95fc7d2445f6b6c79c17725192d1';
  const apiUrl = config?.apiUrl || process.env.LLM_API_URL || 'https://api.deepseek.com/chat/completions';
  const model  = config?.model  || process.env.LLM_MODEL   || 'deepseek-chat';

  

  const payload = JSON.stringify({
    model,
    messages: [
      { role: 'system', content: 'ä½ æ˜¯ä¸€ä¸ª MCP æœåŠ¡åŠ©æ‰‹ï¼Œå¸®åŠ©ç”¨æˆ·æ‰¾åˆ°æˆ–åˆ›å»ºåˆé€‚çš„ MCP æœåŠ¡ã€‚è¯·ç”¨ä¸­æ–‡å›å¤ã€‚' },
      { role: 'user', content: prompt }
    ],
    temperature: 0.7,
    max_tokens: 2048,
    stream: false
  });

  try {
    console.log('ğŸ“¤ å‘é€è¯·æ±‚åˆ° LLM...');
    const raw = await httpsRequest(apiUrl, payload, {
      'Authorization': `Bearer ${apiKey}`
    });

    // å…ˆå°è¯•è§£æä¸º JSON
    let json;
    try {
      json = JSON.parse(raw);
    } catch (parseError) {
      console.error('âŒ å“åº”ä¸æ˜¯æœ‰æ•ˆçš„ JSON:', raw.substring(0, 200));
      throw new Error('LLM è¿”å›äº†æ— æ•ˆçš„å“åº”æ ¼å¼');
    }
    
    // æ£€æŸ¥æ˜¯å¦æœ‰é”™è¯¯
    if (json.error) {
      console.error('âŒ LLM API é”™è¯¯:', json.error);
      // å¦‚æœæ˜¯è®¤è¯é”™è¯¯ï¼Œæä¾›æ›´æ¸…æ™°çš„æç¤º
      if (json.error.code === 'invalid_api_key' || json.error.message?.includes('Authentic')) {
        throw new Error('API Key æ— æ•ˆï¼Œè¯·æ£€æŸ¥ä½ çš„ DeepSeek API Key');
      }
      throw new Error(json.error.message || 'LLM API é”™è¯¯');
    }
    
    if (json.choices && json.choices[0] && json.choices[0].message) {
      return json.choices[0].message.content as string;
    }
    
    console.error('âŒ å“åº”æ ¼å¼ä¸æ­£ç¡®:', json);
    throw new Error('Invalid LLM response format');
  } catch (error) {
    console.error('âŒ LLM è°ƒç”¨å¤±è´¥:', error);
    throw error;
  }
}

export async function parseUserNeed(userInput: string): Promise<ParsedNeed> {
  const prompt = `åˆ†æç”¨æˆ·éœ€æ±‚å¹¶è¿”å› JSON æ ¼å¼çš„ç»“æœã€‚

ç”¨æˆ·éœ€æ±‚ï¼š"${userInput}"

è¯·è¿›è¡Œä»¥ä¸‹8ä¸ªç»´åº¦çš„æ·±åº¦åˆ†æï¼š
1. è¡¨é¢éœ€æ±‚ vs æ·±å±‚åŠ¨æœºï¼šç”¨æˆ·è¯´æƒ³è¦ä»€ä¹ˆï¼Œä½†çœŸæ­£éœ€è¦çš„å¯èƒ½æ˜¯ä»€ä¹ˆï¼Ÿ
2. å‰ç½®æ¡ä»¶ï¼šå®ç°è¿™ä¸ªéœ€æ±‚éœ€è¦å“ªäº›å‰ç½®å‡†å¤‡ï¼Ÿ
3. æ‰§è¡Œè¿‡ç¨‹çš„å›°éš¾ï¼šç”¨æˆ·åœ¨å®ç°è¿‡ç¨‹ä¸­ä¼šé‡åˆ°å“ªäº›æŠ€æœ¯/æ“ä½œéš¾ç‚¹ï¼Ÿ
4. éšæ€§éœ€æ±‚ï¼šç”¨æˆ·æ²¡æœ‰æ˜è¯´ä½†è‚¯å®šéœ€è¦çš„åŠŸèƒ½
5. å·¥ä½œæµç¨‹ï¼šå®Œæˆä»»åŠ¡çš„å…·ä½“æ­¥éª¤
6. æ‰€éœ€å·¥å…·ï¼šæ¯ä¸ªæ­¥éª¤éœ€è¦ä»€ä¹ˆæ ·çš„MCPå·¥å…·
7. è¾¹ç¼˜æƒ…å†µï¼šå¯èƒ½å‡ºç°çš„å¼‚å¸¸æƒ…å†µ
8. åç»­éœ€æ±‚ï¼šå®Œæˆåç”¨æˆ·å¯èƒ½è¿˜éœ€è¦ä»€ä¹ˆ



è¿”å›JSONæ ¼å¼ï¼ˆåªè¿”å›JSONï¼Œä¸è¦æœ‰å…¶ä»–æ–‡å­—ï¼‰ï¼š
{
  "service_type": "æœåŠ¡ç±»å‹",
  "keywords": ["å…³é”®è¯æ•°ç»„"],
  "action": "search",
  "description": "ä¸€å¥è¯æè¿°éœ€æ±‚",
  "deep_need": "æ·±å±‚éœ€æ±‚åˆ†æï¼ˆç”¨æˆ·çœŸæ­£æƒ³è¦è§£å†³çš„é—®é¢˜ï¼‰",
  "workflows": [
    {
      "name": "å·¥ä½œæµåç§°",
      "steps": ["æ­¥éª¤1", "æ­¥éª¤2", "æ­¥éª¤3"]
    }
  ],
  "mcp_tools": [
    {
      "name": "å·¥å…·åç§°",
      "description": "å·¥å…·ç”¨é€”"
    }
  ]
}`;

  try {
    console.log('ğŸ¤– è°ƒç”¨ LLM è¿›è¡Œæ·±åº¦éœ€æ±‚åˆ†æ...');
    const res = await askLLM(prompt);
    
    // å°è¯•æå– JSON
    let jsonStr = res;
    const jsonMatch = res.match(/\{[\s\S]*\}/);
    if (jsonMatch) {
      jsonStr = jsonMatch[0];
    }
    
    const obj = JSON.parse(jsonStr);
    
    // ç¡®ä¿å¿…è¦å­—æ®µå­˜åœ¨
    if (!obj.service_type) obj.service_type = 'general';
    if (!obj.keywords || !Array.isArray(obj.keywords)) obj.keywords = [userInput];
    if (!obj.action) obj.action = 'search';
    if (!obj.description) obj.description = userInput;
    
    console.log('ğŸ§  æ·±åº¦åˆ†æå®Œæˆ:', {
      service_type: obj.service_type,
      has_deep_need: !!obj.deep_need,
      workflows_count: obj.workflows?.length || 0,
      tools_count: obj.mcp_tools?.length || 0
    });
    
    return obj as ParsedNeed;
  } catch (error) {
    console.error('âš ï¸ LLM åˆ†æå¤±è´¥ï¼Œä½¿ç”¨ç®€å•è§£æ:', error);
    
    // æ”¹è¿›çš„å›é€€é€»è¾‘
    const keywords = userInput.split(/\s+/).filter(w => w.length > 1);
    const needsCreate = /åˆ›å»º|å¼€å‘|æ–°å»º|å†™ä¸€ä¸ª|åˆ¶ä½œ/.test(userInput);
    let serviceType = 'general';
    
   
    // è¿”å›åŸºç¡€åˆ†æç»“æœ
    return {
      service_type: serviceType,
      keywords,
      action: needsCreate ? 'create' : 'search',
      description: userInput,
      deep_need: `ç”¨æˆ·æƒ³è¦${needsCreate ? 'åˆ›å»º' : 'æ‰¾åˆ°'}ä¸€ä¸ª${serviceType === 'general' ? '' : serviceType + 'ç›¸å…³çš„'}å·¥å…·æ¥å¤„ç†: ${userInput}`,
      workflows: [{
        name: 'åŸºç¡€æµç¨‹',
        steps: ['æœç´¢ç›¸å…³æœåŠ¡', 'å®‰è£…æˆ–åˆ›å»ºæœåŠ¡', 'ä½¿ç”¨æœåŠ¡å®Œæˆä»»åŠ¡']
      }],
      mcp_tools: [{
        name: `${serviceType}-tool`,
        description: `å¤„ç†${serviceType}ç›¸å…³ä»»åŠ¡çš„å·¥å…·`
      }]
    };
  }
}

export async function generateMCPCode(serviceType: string, keywords: string[], need?: ParsedNeed): Promise<string> {
  let prompt = `ç”Ÿæˆä¸€ä¸ª MCP TypeScript æœåŠ¡ä»£ç ã€‚

æœåŠ¡ç±»å‹: ${serviceType}
å…³é”®è¯: ${keywords.join(', ')}`;

  // å¦‚æœæœ‰æ·±åº¦éœ€æ±‚åˆ†æï¼Œæ·»åŠ åˆ°æç¤ºè¯ä¸­
  if (need) {
    prompt += `

æ·±åº¦éœ€æ±‚åˆ†æ:
- æè¿°: ${need.description}
- æ·±å±‚éœ€æ±‚: ${need.deep_need || 'æ— '}
- å·¥ä½œæµç¨‹: ${need.workflows?.map(w => `${w.name}: ${w.steps.join(' â†’ ')}`).join('; ') || 'æ— '}
- éœ€è¦çš„å·¥å…·: ${need.mcp_tools?.map(t => `${t.name} (${t.description})`).join(', ') || 'æ— '}`;
  }

  prompt += `

è¯·ç”Ÿæˆå®Œæ•´çš„ TypeScript ä»£ç ï¼ŒåŒ…å«æ‰€æœ‰å¿…è¦çš„å¯¼å…¥ã€å·¥å…·å®šä¹‰å’Œå®ç°ã€‚
ä»£ç åº”è¯¥å¯ä»¥ç›´æ¥è¿è¡Œï¼Œå¹¶æä¾›å®é™…æœ‰ç”¨çš„åŠŸèƒ½ã€‚`;

  try {
    const res = await askLLM(prompt);
    
    // æå–ä»£ç å—
    let code = res;
    const codeMatch = res.match(/```(?:typescript|ts)?\n?([\s\S]*?)```/);
    if (codeMatch) {
      code = codeMatch[1].trim();
    } else if (res.includes('import ')) {
      // å¯èƒ½æ•´ä¸ªå“åº”å°±æ˜¯ä»£ç 
      code = res.trim();
    }
    
    return code;
  } catch (error) {
    console.error('âš ï¸ ä»£ç ç”Ÿæˆå¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤æ¨¡æ¿:', error);
    
    // è¿”å›ä¸€ä¸ªåŸºç¡€æ¨¡æ¿
    return `import { Server } from '@modelcontextprotocol/sdk/server/index.js';
import { StdioServerTransport } from '@modelcontextprotocol/sdk/server/stdio.js';
import { z } from 'zod';

const server = new Server({
  name: '${serviceType}-service',
  version: '1.0.0',
}, {
  capabilities: {
    tools: {},
  },
});

// TODO: å®ç° ${serviceType} ç›¸å…³çš„å·¥å…·
server.setRequestHandler('tools/call', async (request) => {
  const { name, arguments: args } = request.params;
  
  // å®ç°ä½ çš„å·¥å…·é€»è¾‘
  return {
    content: [{
      type: 'text',
      text: \`è°ƒç”¨äº†å·¥å…· \${name}\`
    }]
  };
});

server.setRequestHandler('tools/list', async () => {
  return {
    tools: [
      {
        name: 'example_tool',
        description: 'ç¤ºä¾‹å·¥å…·',
        inputSchema: {
          type: 'object',
          properties: {
            input: { type: 'string' }
          }
        }
      }
    ]
  };
});

const transport = new StdioServerTransport();
server.connect(transport);`;
  }
} 